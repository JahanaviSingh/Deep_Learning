{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf12bd71-7ed9-4769-9faa-7c43c246bfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder, CIFAR10\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters (Global)\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5 # Keep low for demonstration, increase to 10-20 for final results\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2362387e-8c20-4f51-b63d-41b4da7d49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(dataset_name):\n",
    "    # Transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)), # Standardize size\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    if dataset_name == 'CIFAR10':\n",
    "        train_set = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "        test_set = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "        num_classes = 10\n",
    "    \n",
    "    elif dataset_name == 'CatsDogs':\n",
    "        \n",
    "        if not os.path.exists('./data/cats_dogs'):\n",
    "            raise FileNotFoundError(\"Please download Cats vs Dogs dataset and place in ./data/cats_dogs\")\n",
    "            \n",
    "        full_dataset = ImageFolder(root='./data/cats_dogs', transform=transform)\n",
    "        # Split into train/test\n",
    "        train_size = int(0.8 * len(full_dataset))\n",
    "        test_size = len(full_dataset) - train_size\n",
    "        train_set, test_set = random_split(full_dataset, [train_size, test_size])\n",
    "        num_classes = 2\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader, num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eae800b-5385-4914-9825-d168fbd2ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes, activation_type='relu', init_type='xavier'):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        self.activation_type = activation_type\n",
    "        self.init_type = init_type\n",
    "        \n",
    "        # Define Layers\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            self.get_activation(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Block 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            self.get_activation(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Block 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            self.get_activation(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128 * 8 * 8, 512), # Assuming input 64x64 -> 8x8 spatial\n",
    "            self.get_activation(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Apply Weight Initialization\n",
    "        self.apply(self.initialize_weights)\n",
    "\n",
    "    def get_activation(self):\n",
    "        if self.activation_type == 'relu':\n",
    "            return nn.ReLU()\n",
    "        elif self.activation_type == 'tanh':\n",
    "            return nn.Tanh()\n",
    "        elif self.activation_type == 'leaky_relu':\n",
    "            return nn.LeakyReLU(0.1)\n",
    "        else:\n",
    "            return nn.ReLU()\n",
    "\n",
    "    def initialize_weights(self, m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            if self.init_type == 'xavier':\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            elif self.init_type == 'kaiming':\n",
    "                nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "            elif self.init_type == 'random':\n",
    "                nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "            \n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e27d8c6-b3a4-43b0-bcd0-0575eb9b2191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        epoch_acc = 100 * correct / total\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        loss_history.append(epoch_loss)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.2f}%\")\n",
    "        \n",
    "    return loss_history\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfacd86f-02f5-413a-a5c4-b9863d4caf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 170M/170M [00:21<00:00, 7.86MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Experiments for CIFAR10 ---\n",
      "\n",
      "Config: Act=relu, Init=xavier, Optim=sgd\n",
      "Epoch [1/3], Loss: 1.5714, Acc: 43.88%\n",
      "Epoch [2/3], Loss: 1.2451, Acc: 55.22%\n",
      "Epoch [3/3], Loss: 1.1088, Acc: 60.49%\n",
      "Test Accuracy: 62.53%\n",
      "\n",
      "Config: Act=relu, Init=xavier, Optim=adam\n",
      "Epoch [1/3], Loss: 1.5022, Acc: 48.61%\n",
      "Epoch [2/3], Loss: 1.0452, Acc: 62.87%\n",
      "Epoch [3/3], Loss: 0.8949, Acc: 68.45%\n",
      "Test Accuracy: 68.88%\n",
      "\n",
      "Config: Act=relu, Init=xavier, Optim=rmsprop\n",
      "Epoch [1/3], Loss: 2.5676, Acc: 40.08%\n",
      "Epoch [2/3], Loss: 1.1909, Acc: 57.18%\n",
      "Epoch [3/3], Loss: 0.9994, Acc: 64.71%\n",
      "Test Accuracy: 64.55%\n",
      "\n",
      "Config: Act=relu, Init=kaiming, Optim=sgd\n",
      "Epoch [1/3], Loss: 1.5995, Acc: 43.25%\n",
      "Epoch [2/3], Loss: 1.2588, Acc: 54.63%\n",
      "Epoch [3/3], Loss: 1.1401, Acc: 59.24%\n",
      "Test Accuracy: 61.27%\n",
      "\n",
      "Config: Act=relu, Init=kaiming, Optim=adam\n",
      "Epoch [1/3], Loss: 1.4878, Acc: 49.21%\n",
      "Epoch [2/3], Loss: 1.0321, Acc: 63.31%\n",
      "Epoch [3/3], Loss: 0.8975, Acc: 68.40%\n",
      "Test Accuracy: 69.99%\n",
      "\n",
      "Config: Act=relu, Init=kaiming, Optim=rmsprop\n",
      "Epoch [1/3], Loss: 2.5414, Acc: 40.47%\n",
      "Epoch [2/3], Loss: 1.1528, Acc: 58.87%\n",
      "Epoch [3/3], Loss: 0.9627, Acc: 65.90%\n",
      "Test Accuracy: 68.02%\n",
      "\n",
      "Config: Act=relu, Init=random, Optim=sgd\n",
      "Epoch [1/3], Loss: 1.5629, Acc: 43.16%\n",
      "Epoch [2/3], Loss: 1.2558, Acc: 54.70%\n",
      "Epoch [3/3], Loss: 1.1150, Acc: 60.16%\n",
      "Test Accuracy: 64.93%\n",
      "\n",
      "Config: Act=relu, Init=random, Optim=adam\n",
      "Epoch [1/3], Loss: 1.4253, Acc: 49.08%\n",
      "Epoch [2/3], Loss: 1.0310, Acc: 63.26%\n",
      "Epoch [3/3], Loss: 0.8766, Acc: 68.82%\n",
      "Test Accuracy: 69.94%\n",
      "\n",
      "Config: Act=relu, Init=random, Optim=rmsprop\n",
      "Epoch [1/3], Loss: 1.6525, Acc: 45.93%\n",
      "Epoch [2/3], Loss: 1.1103, Acc: 60.40%\n",
      "Epoch [3/3], Loss: 0.9532, Acc: 66.18%\n",
      "Test Accuracy: 58.24%\n",
      "\n",
      "Config: Act=tanh, Init=xavier, Optim=sgd\n",
      "Epoch [1/3], Loss: 1.6612, Acc: 41.42%\n",
      "Epoch [2/3], Loss: 1.3461, Acc: 52.11%\n",
      "Epoch [3/3], Loss: 1.1931, Acc: 57.44%\n",
      "Test Accuracy: 60.29%\n",
      "\n",
      "Config: Act=tanh, Init=xavier, Optim=adam\n",
      "Epoch [1/3], Loss: 1.5315, Acc: 45.85%\n",
      "Epoch [2/3], Loss: 1.2369, Acc: 55.83%\n",
      "Epoch [3/3], Loss: 1.1108, Acc: 60.50%\n",
      "Test Accuracy: 61.15%\n",
      "\n",
      "Config: Act=tanh, Init=xavier, Optim=rmsprop\n",
      "Epoch [1/3], Loss: 1.7138, Acc: 40.31%\n",
      "Epoch [2/3], Loss: 1.3492, Acc: 51.61%\n",
      "Epoch [3/3], Loss: 1.2000, Acc: 57.22%\n",
      "Test Accuracy: 55.43%\n",
      "\n",
      "Config: Act=tanh, Init=kaiming, Optim=sgd\n",
      "Epoch [1/3], Loss: 1.6309, Acc: 42.45%\n",
      "Epoch [2/3], Loss: 1.3375, Acc: 52.18%\n",
      "Epoch [3/3], Loss: 1.2160, Acc: 56.57%\n",
      "Test Accuracy: 58.34%\n",
      "\n",
      "Config: Act=tanh, Init=kaiming, Optim=adam\n",
      "Epoch [1/3], Loss: 1.5102, Acc: 46.91%\n",
      "Epoch [2/3], Loss: 1.2133, Acc: 56.59%\n",
      "Epoch [3/3], Loss: 1.0912, Acc: 61.12%\n",
      "Test Accuracy: 61.68%\n",
      "\n",
      "Config: Act=tanh, Init=kaiming, Optim=rmsprop\n",
      "Epoch [1/3], Loss: 1.6272, Acc: 42.96%\n",
      "Epoch [2/3], Loss: 1.3018, Acc: 53.29%\n",
      "Epoch [3/3], Loss: 1.1652, Acc: 58.14%\n",
      "Test Accuracy: 57.90%\n",
      "\n",
      "Config: Act=tanh, Init=random, Optim=sgd\n",
      "Epoch [1/3], Loss: 1.6801, Acc: 39.94%\n",
      "Epoch [2/3], Loss: 1.4040, Acc: 49.81%\n",
      "Epoch [3/3], Loss: 1.2838, Acc: 54.18%\n",
      "Test Accuracy: 57.02%\n",
      "\n",
      "Config: Act=tanh, Init=random, Optim=adam\n",
      "Epoch [1/3], Loss: 1.4570, Acc: 47.54%\n",
      "Epoch [2/3], Loss: 1.1877, Acc: 57.52%\n",
      "Epoch [3/3], Loss: 1.0793, Acc: 61.70%\n",
      "Test Accuracy: 61.20%\n",
      "\n",
      "Config: Act=tanh, Init=random, Optim=rmsprop\n",
      "Epoch [1/3], Loss: 1.5717, Acc: 43.74%\n",
      "Epoch [2/3], Loss: 1.2860, Acc: 54.11%\n",
      "Epoch [3/3], Loss: 1.1676, Acc: 58.29%\n",
      "Test Accuracy: 52.44%\n",
      "\n",
      "Config: Act=leaky_relu, Init=xavier, Optim=sgd\n",
      "Epoch [1/3], Loss: 1.5648, Acc: 44.44%\n",
      "Epoch [2/3], Loss: 1.2314, Acc: 56.00%\n",
      "Epoch [3/3], Loss: 1.1011, Acc: 60.77%\n",
      "Test Accuracy: 64.49%\n",
      "\n",
      "Config: Act=leaky_relu, Init=xavier, Optim=adam\n",
      "Epoch [1/3], Loss: 1.7273, Acc: 44.11%\n",
      "Epoch [2/3], Loss: 1.1190, Acc: 60.64%\n",
      "Epoch [3/3], Loss: 0.9384, Acc: 67.05%\n",
      "Test Accuracy: 68.68%\n",
      "\n",
      "Config: Act=leaky_relu, Init=xavier, Optim=rmsprop\n",
      "Epoch [1/3], Loss: 2.9612, Acc: 37.95%\n",
      "Epoch [2/3], Loss: 1.2565, Acc: 55.23%\n",
      "Epoch [3/3], Loss: 0.9964, Acc: 64.91%\n",
      "Test Accuracy: 61.62%\n",
      "\n",
      "Config: Act=leaky_relu, Init=kaiming, Optim=sgd\n",
      "Epoch [1/3], Loss: 1.6136, Acc: 43.11%\n",
      "Epoch [2/3], Loss: 1.2970, Acc: 53.55%\n",
      "Epoch [3/3], Loss: 1.1866, Acc: 57.90%\n",
      "Test Accuracy: 60.28%\n",
      "\n",
      "Config: Act=leaky_relu, Init=kaiming, Optim=adam\n",
      "Epoch [1/3], Loss: 1.6529, Acc: 46.71%\n",
      "Epoch [2/3], Loss: 1.0917, Acc: 61.55%\n",
      "Epoch [3/3], Loss: 0.9140, Acc: 67.82%\n",
      "Test Accuracy: 70.03%\n",
      "\n",
      "Config: Act=leaky_relu, Init=kaiming, Optim=rmsprop\n",
      "Epoch [1/3], Loss: 2.9989, Acc: 39.35%\n",
      "Epoch [2/3], Loss: 1.2172, Acc: 57.09%\n",
      "Epoch [3/3], Loss: 0.9717, Acc: 65.83%\n",
      "Test Accuracy: 67.33%\n",
      "\n",
      "Config: Act=leaky_relu, Init=random, Optim=sgd\n",
      "Epoch [1/3], Loss: 1.5476, Acc: 43.96%\n",
      "Epoch [2/3], Loss: 1.2418, Acc: 55.50%\n",
      "Epoch [3/3], Loss: 1.1039, Acc: 60.49%\n",
      "Test Accuracy: 65.07%\n",
      "\n",
      "Config: Act=leaky_relu, Init=random, Optim=adam\n",
      "Epoch [1/3], Loss: 1.4320, Acc: 49.02%\n",
      "Epoch [2/3], Loss: 1.0333, Acc: 63.41%\n",
      "Epoch [3/3], Loss: 0.8580, Acc: 69.90%\n",
      "Test Accuracy: 71.51%\n",
      "\n",
      "Config: Act=leaky_relu, Init=random, Optim=rmsprop\n",
      "Epoch [1/3], Loss: 1.9470, Acc: 42.51%\n",
      "Epoch [2/3], Loss: 1.1552, Acc: 58.51%\n",
      "Epoch [3/3], Loss: 0.9394, Acc: 66.70%\n",
      "Test Accuracy: 56.84%\n",
      "\n",
      "Best CIFAR10 Accuracy: 71.51% with Config: leaky_relu_random_adam\n"
     ]
    }
   ],
   "source": [
    "def run_experiments(dataset_name):\n",
    "    train_loader, test_loader, num_classes = get_dataloaders(dataset_name)\n",
    "    \n",
    "    # Configurations\n",
    "    activations = ['relu', 'tanh', 'leaky_relu']\n",
    "    initializations = ['xavier', 'kaiming', 'random']\n",
    "    optimizers_list = ['sgd', 'adam', 'rmsprop']\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_model = None\n",
    "    best_config = \"\"\n",
    "    \n",
    "    # Create directory for weights\n",
    "    os.makedirs(f'weights/{dataset_name}', exist_ok=True)\n",
    "\n",
    "    print(f\"--- Starting Experiments for {dataset_name} ---\")\n",
    "    \n",
    "    # NOTE: Running all 27 combinations takes a long time. \n",
    "    # For demonstration, we will loop through one list while keeping others constant\n",
    "    # You should un-comment the nested loops for the full lab requirement.\n",
    "    \n",
    "    # Full loop structure:\n",
    "    for act in activations:\n",
    "        for init in initializations:\n",
    "             for opt_name in optimizers_list:\n",
    "                print(f\"\\nConfig: Act={act}, Init={init}, Optim={opt_name}\")\n",
    "                \n",
    "                model = CustomCNN(num_classes=num_classes, activation_type=act, init_type=init).to(device)\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                \n",
    "                if opt_name == 'sgd':\n",
    "                    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "                elif opt_name == 'adam':\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "                elif opt_name == 'rmsprop':\n",
    "                    optimizer = optim.RMSprop(model.parameters(), lr=LEARNING_RATE)\n",
    "                \n",
    "                _ = train_model(model, train_loader, criterion, optimizer, epochs=3) # Low epochs for speed\n",
    "                acc = evaluate_model(model, test_loader)\n",
    "                \n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_model = model\n",
    "                    best_config = f\"{act}_{init}_{opt_name}\"\n",
    "                    torch.save(model.state_dict(), f'weights/{dataset_name}/best_model.pth')\n",
    "    \n",
    "    print(f\"\\nBest {dataset_name} Accuracy: {best_acc:.2f}% with Config: {best_config}\")\n",
    "    return best_model, num_classes, test_loader\n",
    "\n",
    "# Run for CIFAR-10\n",
    "best_cnn_cifar, num_classes_cifar, test_loader_cifar = run_experiments('CIFAR10')\n",
    "\n",
    "# Run for Cats vs Dogs (Uncomment if data is present)\n",
    "# best_cnn_cats, num_classes_cats, test_loader_cats = run_experiments('CatsDogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "731ad2a6-caf5-44e3-a491-fdbef6c0c0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fine-tuning ResNet-18 for CIFAR10 ---\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/jahanavisingh/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 44.7M/44.7M [00:09<00:00, 5.02MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.2357, Acc: 58.10%\n",
      "Epoch [2/5], Loss: 1.0738, Acc: 63.79%\n",
      "Epoch [3/5], Loss: 1.0525, Acc: 64.47%\n",
      "Epoch [4/5], Loss: 1.0417, Acc: 64.35%\n",
      "Epoch [5/5], Loss: 1.0364, Acc: 64.89%\n",
      "Test Accuracy: 64.75%\n",
      "ResNet18 Accuracy: 64.75%\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "def train_resnet(dataset_name, test_loader, num_classes):\n",
    "    print(f\"\\n--- Fine-tuning ResNet-18 for {dataset_name} ---\")\n",
    "    \n",
    "    # Load Pretrained Model\n",
    "    resnet = models.resnet18(weights='IMAGENET1K_V1')\n",
    "    \n",
    "    # Freeze initial layers (optional, but good for small datasets)\n",
    "    for param in resnet.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    # Modify the final Fully Connected layer\n",
    "    num_ftrs = resnet.fc.in_features\n",
    "    resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    resnet = resnet.to(device)\n",
    "    \n",
    "    # Only optimize the final layer\n",
    "    optimizer = optim.Adam(resnet.fc.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Get dataloaders again\n",
    "    train_loader, _, _ = get_dataloaders(dataset_name)\n",
    "    \n",
    "    # Train\n",
    "    train_model(resnet, train_loader, criterion, optimizer, epochs=5)\n",
    "    acc = evaluate_model(resnet, test_loader)\n",
    "    \n",
    "    torch.save(resnet.state_dict(), f'weights/{dataset_name}/resnet18_finetuned.pth')\n",
    "    return acc\n",
    "\n",
    "# Compare\n",
    "resnet_acc_cifar = train_resnet('CIFAR10', test_loader_cifar, num_classes_cifar)\n",
    "print(f\"ResNet18 Accuracy: {resnet_acc_cifar:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e389f45d-26c8-478c-883e-ea58b1a9bf45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
